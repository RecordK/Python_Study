# -*- coding: utf-8 -*-
"""d0217

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xrGRngyVOQHOijFTCnFRDsYPSsg1Sfk9
"""

!pip install selenium
!apt-get update
!apt install chromium-chromedriver

from selenium import webdriver
from urllib.request import urlopen
from bs4 import BeautifulSoup as bs
from urllib.parse import quote_plus
from selenium.webdriver.common.keys import Keys
import time
import requests
import pandas as pd
url = 'https://www.kobis.or.kr/kobis/business/stat/boxs/findRealTicketList.do'

html = requests.get(url, headers={'User-agent': 'Mozilla/5.0'}).text
a = pd.read_html(html)[0]
a = a.dropna()#NAN 줄 제거
a

chrome_options = webdriver.ChromeOptions()
chrome_options.add_argument('--headless')
chrome_options.add_argument('--no-sandbox')
chrome_options.add_argument('--disable-dev-shm-usage')
driver = webdriver.Chrome('chromedriver', chrome_options=chrome_options)

driver.get('https://www.kobis.or.kr/kobis/business/stat/boxs/findRealTicketList.do')
driver.find_element_by_xpath('//*[@id="searchForm"]/div/div[4]/button[1]').click()
time.sleep(3)
tbl = driver.find_element_by_css_selector('#content > div.rst_sch > table')
tbody = tbl.find_element_by_tag_name("tbody")
rows = tbody.find_elements_by_tag_name("tr")
for index, value in enumerate(rows):
    tds=value.find_elements_by_tag_name("td")
    print(tds[0].text+'.'+tds[1].text)

html = requests.get('http://www.kma.go.kr/weather/forecast/mid-term-rss3.jsp').text  #웹 요청
#html=html.decode('utf-8')
#지역별 일간 날씨를 출력
root = bs(html, 'html.parser') 
loc = root.find_all('location')
for i in loc:  # i:<location>
    print(i.city.get_text(), '지역 날씨========')
    d = i.find_all('data')
    for j in d: # j:<data>
        print(j.tmef.string , ':', j.wf.string, ' / 최저온도:', j.tmn.string, ' / 최고온도:', j.tmx.string, ' / 습도:',j.rnst.string,'%')

url = 'https://ent.sbs.co.kr/news/flash.do?plink=GNB&cooper=SBSENTERNEWS'
html = requests.get(url).text  
root = bs(html, 'html.parser') 
divs = root.select('div.w_nwl_text')#기사 div 태그들만 추출
divs

for i in divs:
    title = i.find('h3').text
    print('title:', title)
    #select는 여러개검색하는 함수이므로 반환타입이 []리스트다
    text = i.select('div.nwl_text')[0].text  
    print('text:', text)
    writer = i.select('em.nwl_reporter')[0].text
    print('writer:', writer)
    time = i.select('div.nwl_subtext')[0].text
    print('time:', time)
    print('====================')

import json
f = open('/content/drive/MyDrive/serviceAreaFoods.json','r',encoding='utf-8')

json_data = json.load(f)
food1 = json_data['http://data.ex.co.kr:80/link/serviceAreaFoods/B00099']
print('가격:', food1['http://data.ex.co.kr:80/link/def/salePrice'][0]['value'])
print('메뉴명:', food1['http://data.ex.co.kr:80/link/def/batchMenu'][0]['value'])
print('지역명:', food1['http://data.ex.co.kr:80/link/def/serviceAreaName'][0]['value'])
print('고속도로명:', food1['http://data.ex.co.kr:80/link/def/routeName'][0]['value'])
print('방향:', food1['http://data.ex.co.kr:80/link/def/direction'][0]['value'])

df=pd.read_json('/content/drive/MyDrive/serviceAreaFoods.json','r',encoding='utf-8')

df=df.T

df=df.drop('http://www.w3.org/2000/01/rdf-schema#label',axis=1)

df.columns=['가격','메뉴명','지역명','고속도로명','방향']

df.index=[i for i in range(1,169)]

df.iloc[0].values

for i in df.columns.values:
  print(df[i].str.split("'value': '"))

# json 
for i in json_data: # 음식 하나씩 추출
    food_data = json_data[i]
    for j in food_data: # 음식 정보를 하나씩 추출
        ss = j.split('/')
        title = ss[len(ss)-1]
        data = food_data[j]
        print(title,':',data[0]['value'])
    print('========================')

